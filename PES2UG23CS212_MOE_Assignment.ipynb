{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Unit 2 Assignment: Building a Mixture of Experts (MoE) Router\n",
        "\n",
        "Name : Harsha Madev Hegde\n",
        "\n",
        "SRN : PES2UG23CS212\n",
        "\n",
        "Section D\n"
      ],
      "metadata": {
        "id": "eVO3hnf7X9-w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing Dependencies"
      ],
      "metadata": {
        "id": "Oak_ZdQDYK8f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJB-mVMvX8lh",
        "outputId": "90beaa1b-729e-47b6-f2d6-9e983aa2442f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-1.0.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.2)\n",
            "Downloading groq-1.0.0-py3-none-any.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install groq python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up API Key"
      ],
      "metadata": {
        "id": "I1Z92PKCYWEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Secure API key input (hidden textbox)\n",
        "\n",
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "# This creates a hidden input field\n",
        "api_key = getpass(\"Enter GROQ API Key: \")\n",
        "\n",
        "# Store in environment variable\n",
        "os.environ[\"GROQ_API_KEY\"] = api_key\n",
        "\n",
        "print(\"✅ API key loaded securely.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDYpS1QWYfRx",
        "outputId": "f7a2c226-97c7-4100-eb58-ae7ab161036c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter GROQ API Key: ··········\n",
            "✅ API key loaded securely.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing and Initializing Groq Client"
      ],
      "metadata": {
        "id": "iDMB5HqCZfbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "import os\n",
        "\n",
        "client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
        "\n",
        "MODEL_NAME = \"llama-3.1-8b-instant\""
      ],
      "metadata": {
        "id": "QHaWY6BMZhwg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining Expert Configurations"
      ],
      "metadata": {
        "id": "BEpzVrmFZmUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_CONFIG = {\n",
        "    \"technical\": {\n",
        "        \"system_prompt\": (\n",
        "            \"You are a Technical Support Expert. \"\n",
        "            \"Be precise, logical, and code-focused. \"\n",
        "            \"Explain bugs clearly and provide corrected code when necessary.\"\n",
        "        ),\n",
        "        \"temperature\": 0.7\n",
        "    },\n",
        "    \"billing\": {\n",
        "        \"system_prompt\": (\n",
        "            \"You are a Billing Support Expert. \"\n",
        "            \"Be empathetic, professional, and policy-driven. \"\n",
        "            \"Explain billing issues and refund policies clearly.\"\n",
        "        ),\n",
        "        \"temperature\": 0.7\n",
        "    },\n",
        "    \"general\": {\n",
        "        \"system_prompt\": (\n",
        "            \"You are a friendly general assistant. \"\n",
        "            \"Respond helpfully and conversationally.\"\n",
        "        ),\n",
        "        \"temperature\": 0.7\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "XY6zMQfNZobh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Router Function (Temperature = 0)"
      ],
      "metadata": {
        "id": "zT_FL3JOZvjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def route_prompt(user_input):\n",
        "    routing_prompt = f\"\"\"\n",
        "Classify the following user query into one of these categories:\n",
        "[technical, billing, general]\n",
        "\n",
        "Return ONLY the category name.\n",
        "\n",
        "User Query:\n",
        "{user_input}\n",
        "\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL_NAME,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a strict classifier.\"},\n",
        "            {\"role\": \"user\", \"content\": routing_prompt}\n",
        "        ],\n",
        "        temperature=0\n",
        "    )\n",
        "\n",
        "    category = response.choices[0].message.content.strip().lower()\n",
        "    return category"
      ],
      "metadata": {
        "id": "mdNhlKsxZrnY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Orchestrator Function"
      ],
      "metadata": {
        "id": "ynKEDpi1Z0W8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_request(user_input):\n",
        "    category = route_prompt(user_input)\n",
        "\n",
        "    # Safety fallback\n",
        "    if category not in MODEL_CONFIG:\n",
        "        category = \"general\"\n",
        "\n",
        "    config = MODEL_CONFIG[category]\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL_NAME,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": config[\"system_prompt\"]},\n",
        "            {\"role\": \"user\", \"content\": user_input}\n",
        "        ],\n",
        "        temperature=config[\"temperature\"]\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"routed_to\": category,\n",
        "        \"response\": response.choices[0].message.content\n",
        "    }"
      ],
      "metadata": {
        "id": "KWs4pHmNZ19l"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing With Example Inputs"
      ],
      "metadata": {
        "id": "7fKQW9NTZ5Sk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 1: Technical\n",
        "print(process_request(\"My python script is throwing an IndexError on line 5.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIe-0tkwZ6sN",
        "outputId": "38763a67-3624-4eca-d582-637446cd13e8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'routed_to': 'technical', 'response': \"To troubleshoot the issue, I'll need more information about your code. However, I can guide you through a general process.\\n\\n**General Steps to Troubleshoot an IndexError**\\n\\n1. **Identify the line number**: You've already mentioned that the error occurs on line 5. I'll make sure to refer to that line.\\n2. **Check the indexing**: An IndexError typically occurs when you're trying to access an element in a list or other sequence that doesn't exist.\\n3. **Verify the length of the sequence**: Make sure the sequence you're trying to access has at least as many elements as you're trying to access.\\n\\n**Example Code for a Common Scenario**\\n\\nHere's an example of a simple list with an IndexError:\\n```python\\nmy_list = [1, 2, 3]\\nprint(my_list[3])  # This will raise an IndexError\\n```\\nIn this case, the error occurs because the list `my_list` only has three elements (at indices 0, 1, and 2), but we're trying to access the fourth element (index 3).\\n\\n**Your Code**\\n\\nPlease provide the code from line 5 to help me understand the issue better. If you're not sure where to start, you can share the entire code, and I'll do my best to assist you.\\n\\n**How I'll Help**\\n\\nOnce I have your code, I'll:\\n\\n1. Identify the line that's causing the error.\\n2. Analyze the code to determine why the error is occurring.\\n3. Provide a clear explanation of the issue.\\n4. Offer corrected code (if necessary).\\n\\nLet's get started! Please share your code.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2: Billing\n",
        "print(process_request(\"I was charged twice for my subscription this month.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUwtB9AtaR3e",
        "outputId": "4bfaeee4-f8b9-42c8-843f-1f43e6038fa3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'routed_to': 'billing', 'response': \"I'm so sorry to hear that you were charged twice for your subscription. That can be frustrating and confusing. \\n\\nI'd like to assure you that we take situations like this very seriously and I'm here to help resolve the issue for you. To better assist you, can you please provide me with some information? Could you tell me:\\n\\n1. The date you were initially charged for your subscription?\\n2. The date you were charged the second time?\\n3. The total amount charged on both occasions?\\n4. The payment method used for the subscription?\\n\\nThis information will help me investigate the issue and ensure that the duplicate charge is removed from your account.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 3: General\n",
        "print(process_request(\"Tell me something interesting about space.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHrEPkIUaTqP",
        "outputId": "a2f55750-db89-4a1f-ccd5-f7fb0c6d7d5a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'routed_to': 'general', 'response': \"There's a fascinating fact about space that I'd love to share with you. Did you know that there's a giant storm on Jupiter that's been raging for at least 187 years? This massive storm is called the Great Red Spot, and it's a persistent anticyclonic storm that's so large it could swallow several Earths whole.\\n\\nThe Great Red Spot is a swirling storm of clouds that's about 10,000 miles wide and 25,000 miles long. It's a massive system of clouds that's been observed by astronomers for centuries, and it's still one of the most iconic features of the planet Jupiter.\\n\\nThe storm is thought to be a high-pressure region with strong winds that can reach speeds of up to 400 miles per hour. The exact cause of the storm's persistence is still a topic of debate among scientists, but it's believed to be due to a combination of Jupiter's internal heat and the planet's atmospheric circulation patterns.\\n\\nWhat's even more amazing is that the Great Red Spot is still active and continues to evolve to this day. Astronomers have been observing the storm for centuries, and it's still a source of fascination for scientists and space enthusiasts alike.\\n\\nWould you like to know more about space or is there something else I can help you with?\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For user's input questions"
      ],
      "metadata": {
        "id": "Z2apxxEHacHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    user_input = input(\"\\nAsk something (type 'exit' to quit): \")\n",
        "    if user_input.lower() == \"exit\":\n",
        "        break\n",
        "\n",
        "    result = process_request(user_input)\n",
        "    print(\"\\nRouted To:\", result[\"routed_to\"])\n",
        "    print(\"Response:\", result[\"response\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_Ej5H57aegY",
        "outputId": "60658e33-520a-4fee-afbc-c9d582bf7e1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ask something (type 'exit' to quit): tell me something about educatio\n",
            "\n",
            "Routed To: general\n",
            "Response: Education is a fascinating topic. Did you know that the concept of education dates back to ancient civilizations, with evidence of formal education systems in ancient Greece, Rome, and Egypt?\n",
            "\n",
            "In ancient Greece, for example, education was reserved for the wealthy and focused on developing the mind through the study of philosophy, literature, and the arts. The famous philosopher Socrates is said to have believed that education should be a lifelong process of questioning and exploring ideas.\n",
            "\n",
            "Fast-forward to the present day, and education has evolved significantly. We now have a much more inclusive and diverse education system, with access to education for people of all ages, backgrounds, and abilities.\n",
            "\n",
            "Some interesting trends in modern education include:\n",
            "\n",
            "1. **Online learning**: With the rise of the internet and digital technology, online learning has become increasingly popular. Many universities and educational institutions now offer online courses and degree programs, making it easier for people to access education from anywhere in the world.\n",
            "2. **Personalized learning**: With the help of AI and machine learning, education is becoming more personalized. Teachers can now tailor their teaching to the individual needs and learning styles of each student, leading to better outcomes and increased engagement.\n",
            "3. **STEM education**: Science, Technology, Engineering, and Math (STEM) education is becoming increasingly important in today's world. These subjects are essential for careers in fields like technology, healthcare, and environmental sustainability.\n",
            "4. **Social-emotional learning**: There's a growing recognition of the importance of social-emotional learning (SEL) in education. SEL involves teaching students skills like empathy, self-awareness, and conflict resolution, which are essential for success in both personal and professional life.\n",
            "\n",
            "What aspects of education interest you the most?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final conclusion\n",
        "\n",
        "\n",
        "In this assignment, we implemented a Mixture of Experts (MoE) architecture to build a Smart Customer Support Router\n",
        "\n",
        "Assignment_MOE\n",
        "\n",
        ".\n",
        "\n",
        "The system uses an LLM-based router with temperature set to 0 to classify user queries into predefined categories (technical, billing, general). Based on the classification, the request is forwarded to a specialized expert configuration using different system prompts and a higher temperature for flexible responses.\n",
        "\n",
        "This approach demonstrates how a single base LLM can simulate multiple domain experts through prompt engineering. The architecture is modular, scalable, and reflects real-world AI system design principles used in production environments."
      ],
      "metadata": {
        "id": "KzrO9fiJbDM2"
      }
    }
  ]
}